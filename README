I created this project so that I could extract words from Japanese text so that
I could create flashcards to study them without having to manually look each
one up individually.

Obviously lists like this have been compiled elsewhere, the most common coming
from newspaper. I wanted something more focused as for example programming
materials will use far difficult vocabulary compared to a popular comic.

In English this would be a rather simple prospect, read in the files, split
on whitespace or punctuation characters and call it a day. Japanese does
not differentiation words using whitespace, making this a bit more challenging.

Modern Japanese is composed of three different alphabets:

Hiragana - an alphabet of about 50 letters used as a base language to represent
    sounds, as well as to conjugate verbs, and anything that kanji does not
    cover.
Katakana - an alphabet mirroring the hiragana alphabet, it is primary used for
    foreign loan words.
Kanji - Over 2,000 ideographs representing objects, ideas, etc.

Generally a sentence will contain Kanji for nouns, verbs, and adjectives, with
Hiragana used for conjugation purposes or to provide markers for sentence
sections.

The way most Japanese programs handle this problem is compare a given section
of text to a weighted list of words, often with grammatical analysis.

Until that can be implemented this project will use a simpler method of
analyzing the text of a sentence looking for alphabet changes. In general
this should isolate nouns, verbs, adjectives, etc. and will fail to break
up compound words as well as fail to recognize verb conjugations.
